{
  "models": {
    "JudgeResult": {
      "additionalProperties": false,
      "description": "The schema for the evaluation output of the judge model.",
      "properties": {
        "reasons": {
          "description": "A list of specific reasons or feedback supporting the verdict.",
          "items": {
            "type": "string"
          },
          "title": "Reasons",
          "type": "array"
        },
        "score": {
          "description": "The numerical quality score from 0 to 100.",
          "maximum": 100,
          "minimum": 0,
          "title": "Score",
          "type": "integer"
        },
        "verdict": {
          "description": "The final pass/fail decision for the generated content.",
          "enum": [
            "PASS",
            "FAIL"
          ],
          "title": "Verdict",
          "type": "string"
        }
      },
      "required": [
        "verdict",
        "score"
      ],
      "title": "JudgeResult",
      "type": "object"
    },
    "LLMOutput": {
      "$defs": {
        "QuestionItem": {
          "additionalProperties": false,
          "description": "Represents a single generated interview question and its evaluation metadata.",
          "properties": {
            "example_answer_bad": {
              "description": "A poor example answer or one containing red flags.",
              "title": "Example Answer Bad",
              "type": "string"
            },
            "example_answer_good": {
              "description": "A high-quality example answer demonstrating desired competency.",
              "title": "Example Answer Good",
              "type": "string"
            },
            "example_answer_mid": {
              "description": "An average example answer showing basic understanding but lacking depth.",
              "title": "Example Answer Mid",
              "type": "string"
            },
            "grading_rubrics": {
              "description": "Detailed grading criteria with 'Good:', 'To avoid:', and 'Red Flag:' sections.",
              "title": "Grading Rubrics",
              "type": "string"
            },
            "question_id": {
              "description": "The unique identifier for the question, preserved from the input context.",
              "title": "Question Id",
              "type": "string"
            },
            "question_name": {
              "description": "A short, descriptive title for the question topic.",
              "title": "Question Name",
              "type": "string"
            },
            "question_text": {
              "description": "The actual interrogative interview question. Must be at least 10 words and end with a question mark.",
              "title": "Question Text",
              "type": "string"
            }
          },
          "required": [
            "question_id",
            "question_name",
            "question_text",
            "example_answer_good",
            "example_answer_mid",
            "example_answer_bad",
            "grading_rubrics"
          ],
          "title": "QuestionItem",
          "type": "object"
        }
      },
      "additionalProperties": false,
      "description": "The root schema for the LLM's structured question generation response.",
      "properties": {
        "questions": {
          "description": "A list containing all generated questions for the specified role.",
          "items": {
            "$ref": "#/$defs/QuestionItem"
          },
          "title": "Questions",
          "type": "array"
        }
      },
      "required": [
        "questions"
      ],
      "title": "LLMOutput",
      "type": "object"
    }
  },
  "title": "LLM Schema",
  "type": "object"
}
