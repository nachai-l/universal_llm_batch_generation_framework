{
  "models": {
    "JudgeResult": {
      "additionalProperties": false,
      "description": "The structured output for evaluating or judging a specific input or response.",
      "properties": {
        "reasons": {
          "description": "A list of specific justifications for the assigned score and verdict.",
          "items": {
            "type": "string"
          },
          "title": "Reasons",
          "type": "array"
        },
        "score": {
          "description": "The numerical score assigned to the output (0 to 100).",
          "maximum": 100,
          "minimum": 0,
          "title": "Score",
          "type": "integer"
        },
        "verdict": {
          "description": "The final pass/fail decision based on the evaluation.",
          "enum": [
            "PASS",
            "FAIL"
          ],
          "title": "Verdict",
          "type": "string"
        }
      },
      "required": [
        "verdict",
        "score"
      ],
      "title": "JudgeResult",
      "type": "object"
    },
    "LLMOutput": {
      "$defs": {
        "QuestionItem": {
          "additionalProperties": false,
          "description": "Represents an individual interview question with metadata and grading criteria.",
          "properties": {
            "example_answer_bad": {
              "description": "A poor response that is vague, generic, or misaligned with the role expectations.",
              "title": "Example Answer Bad",
              "type": "string"
            },
            "example_answer_good": {
              "description": "A strong, concrete, and structured response following the STAR method.",
              "title": "Example Answer Good",
              "type": "string"
            },
            "example_answer_mid": {
              "description": "A mediocre response that is partially structured but lacks depth or specific details.",
              "title": "Example Answer Mid",
              "type": "string"
            },
            "grading_rubrics": {
              "description": "Detailed evaluation criteria covering intent, structure, depth, clarity, and relevance.",
              "title": "Grading Rubrics",
              "type": "string"
            },
            "question_id": {
              "description": "The unique identifier for the question, preserved from context.",
              "title": "Question Id",
              "type": "string"
            },
            "question_name": {
              "description": "The interrogative interview question text (at least 10 words, ends with ?).",
              "title": "Question Name",
              "type": "string"
            }
          },
          "required": [
            "question_id",
            "question_name",
            "example_answer_good",
            "example_answer_mid",
            "example_answer_bad",
            "grading_rubrics"
          ],
          "title": "QuestionItem",
          "type": "object"
        }
      },
      "additionalProperties": false,
      "description": "The complete structured output containing a list of generated interview questions.",
      "properties": {
        "questions": {
          "description": "A list of question objects generated for the specified role.",
          "items": {
            "$ref": "#/$defs/QuestionItem"
          },
          "title": "Questions",
          "type": "array"
        }
      },
      "required": [
        "questions"
      ],
      "title": "LLMOutput",
      "type": "object"
    }
  },
  "title": "LLM Schema",
  "type": "object"
}
