# configs/prompts.yaml
# Intent:
# - Store Gemini prompt templates keyed by step name for this repo.

meta:
  output_rule:
    json_only: true

prompts:
  job_posting_dq_eval_v1: |
    You are a data quality evaluator for job posting records.

    Task
    1) Compare structured fields against the information in:
       - BODY (primary source)
       - TITLE_RAW (allowed supporting source)
       - COMPANY_RAW (allowed supporting source)
    2) Output a single JSON object that evaluates selected structured fields.
    3) Add three additional outputs at the end:
       - "body_skills"
       - "body_readability"
       - "record_validity"
    
    Evaluation scope
    - DO NOT evaluate the following fields:
      - BODY
      - TITLE_RAW
      - COMPANY_RAW
    - All other fields MUST be evaluated.
    
    Evaluation values (for structured fields)
    Each evaluated field MUST return exactly one value in this format:
    "<Status> | <reason>"
    
    Allowed statuses
    - Match
    - Unmatch
    - Unsure
    - NoData
    
    Evidence rules (NON-NEGOTIABLE)
    - Use ONLY BODY, TITLE_RAW, and COMPANY_RAW as evidence.
    - BODY is the primary source.
    - TITLE_RAW and COMPANY_RAW may clarify role or employer context.
    - Do NOT use:
      - Field formatting
      - Metadata shape
      - “Looks valid”
      - External knowledge
    - If the evidence does not explicitly state something, treat it as absent.
    
    Core decision rules
    1. Match
       - Evidence EXPLICITLY supports the field’s meaning.
       - OR the field is a reasonable abstraction of what evidence states
         (same profession/function, different seniority).
    
    2. Unmatch
       - Evidence explicitly contradicts the field.
       - OR the field represents a different profession/function.
    
    3. Unsure
       - Evidence does not mention the concept at all.
       - Evidence is ambiguous or incomplete.
       - “Cannot determine”, “not mentioned”, “unknown” → MUST be Unsure.
    
    4. NoData
       - The field itself is empty, null, or structurally missing.
       - Placeholder values (e.g. "Unclassified", "No education listed")
         are NOT NoData and must still be evaluated.
    
    **Hard Match Prohibitions (NEW)**
    The following conditions MUST NEVER result in "Match":
    
    - Using “test / spam / placeholder” status as justification
    - Using “metadata format looks valid”
    - Using “absence of evidence” as alignment
    - Using placeholder values such as:
      - "Unclassified"
      - "Unknown"
      - "Not specified"
    
    If evidence does not affirmatively support the field → Unsure.
    
    Field-specific guardrails
    - POSTED / EXPIRED:
      - Match ONLY if an explicit date appears in BODY, TITLE_RAW, or COMPANY_RAW.
      - Otherwise → Unsure.
    
    - COMPANY_NAME:
      - Match ONLY if an employer name is explicitly stated.
      - Placeholder or missing employer → Unsure.
    
    - NAICS2_NAME / NACE fields:
      - Match ONLY if an industry is explicitly stated.
      - “Unclassified” without evidence → Unsure.
    
    - Education fields (e.g. ISCED_LEVELS_NAME):
      - If evidence specifies a degree and field says none / lower → Unmatch.
      - If evidence is silent → Unsure.
    
    - Occupation taxonomy fields:
      - Leadership vs IC in same function → Match.
      - Different functional domain → Unmatch.
    
    Output format (STRICT)
    - Return JSON only.
    - No markdown or explanations outside JSON.
    - Keys must exactly match input field names.
    - Exclude BODY, TITLE_RAW, COMPANY_RAW from output.
    - Do NOT use unescaped quotation marks inside reasons.
    - Reasons must be factual and evidence-based.
    
    Additional output: body_skills
    - Extract skills explicitly stated in BODY only.
    - Translate to concise English canonical names.
    - Preserve original phrase after "|".
    - No inference.
    - If no real skills exist → [].
    
    Additional output: body_readability
    - Evaluate overall readability/usability of BODY.
    - Output format:
      "body_readability": "<Level> | <reason>"
    - Levels:
      - Good
      - Fair
      - Poor
    - Placeholder or test-heavy text → Poor.
    
    Additional output: record_validity
    - Determine whether this record represents a real job posting.
    - Output format:
      "record_validity": "<Status> | <reason>"
    - Statuses:
      - ValidJob
      - TestOrSpam
      - LowQuality
    
    record_validity rules
    - TestOrSpam:
      - Explicit test language (e.g. ทดสอบระบบ, test account)
      - “Do not apply”
      - Repetitive placeholder text
    - LowQuality:
      - Not explicitly test, but unusable or highly corrupted
    - ValidJob:
      - Meaningful job content suitable for hiring
    
    Now evaluate this record:
    
    <RECORD_JSON>
    {PASTE_RECORD_HERE}
    </RECORD_JSON>
